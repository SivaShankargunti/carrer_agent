!pip install -qU langchain-google-genai
!pip install  langchain langchain_community

from google.colab import userdata
API_KEY=userdata.get('GOOGLE_API_KEY')

from langchain_google_genai import ChatGoogleGenerativeAI
model = ChatGoogleGenerativeAI(model="gemini-2.5-flash", api_key=API_KEY)
response= model.invoke("what is your knowlage cutoff date")
print(response.content)

from google.colab import userdata
SEARCH_API_KEY=userdata.get('TAVILY_API_KEY')

from langchain.agents import initialize_agent
from langchain_community.tools import TavilySearchResults
search= TavilySearchResults(tavily_api_key=SEARCH_API_KEY)
tools = [search]
agent = initialize_agent(tools= tools, llm=model, agent="zero-shot-react-description", verbose=True, handle_parsing_errors=True)
agent.invoke("who is current deputy CM of andhra pradesh")

response= model.invoke("who is current deputy CM of andhra pradesh")
print(response.content)


!pip install  -U langgraph
!pip install tavily-Python langgraph



from typing import List
from langchain_core.messages import HumanMessage,BaseMessage,AIMessage
from langchain_core.tools import tool
from tavily import TavilyClient
from langgraph.graph import MessageGraph,END
tavilt=TavilyClient(api_key = SEARCH_API_KEY)



#------tools------


@tool
def parse_resume(text:str)->str:
  """ Extract skill,role,year of experience from resume text"""
  prompt=f"Extract structed info like skill,roles,year of experience from this resume:/n/n{text}"
  return model.invoke([HumanMessage(content=prompt)]).content
@tool

def search_job_tavily(query:str)-> str:
  """search for jobs using tavily and returns summarized result"""
  results = tavilt.search(query)
  print(results)
  return results["results"]


#-----nodes------


def profile_node(state:list[BaseMessage])->list[BaseMessage]:
  resume=state[-1].content
  profile=parse_resume.invoke(resume)
  return state+[AIMessage(content=f"extracted profile:\n{profile}")]


def job_search_node(state:list[BaseMessage])->list[BaseMessage]:
  profile=state[-1].content
  query=model.invoke([HumanMessage(content=f"based on this profile, write a job search query:{profile},keep the query very short for search engines to search")]).content
  jobs=search_job_tavily.invoke(query)
  return state+[AIMessage(content=f"jobs found:\n{jobs}")]

def matched_node(state:list[BaseMessage])->list[BaseMessage]:
  jobs=state[-1].content
  profile=state[-2].content
  prompt=f"given this profile:\n{profile}\n\n rank and recommend top 3 jobs from :\n{jobs}"
  ranked= model.invoke([HumanMessage(content=prompt)])
  return state+[ranked]

def cover_letter_node(state:list[BaseMessage])->list[BaseMessage]:
  profile= state[-3].content
  best_job=state[-1].content
  prompt=f"write a personalized shart-medium cover letter for thos job info:\n\n {best_job}\n\n based on profile\n {profile}"
  letter=model.invoke([HumanMessage(content=prompt)])
  return state+[letter]


#-----langgraph-------
graph=MessageGraph()


graph.add_node("profile",profile_node)
graph.add_node("search",job_search_node)
graph.add_node("matched",matched_node)
graph.add_node("cover",cover_letter_node)

graph.set_entry_point("profile")

graph.add_edge("profile","search")
graph.add_edge("search","matched")
graph.add_edge("matched","cover")
graph.add_edge("cover",END)


app=graph.compile()

#-----run example------

input_msg=HumanMessage(content="search a job for me,i am startup builder i have one year experences data management, i developed skills in below ,search jobs my acoording my skills as a fresher  to taht, sysytems i know about the python, prompt engineer,langchain, ai agent and,1)i am builded project like on RAG with custom data ,2)using langchain build ai agent with and with search tools ,like tavily ,3)buliding chat bot with and without memory, 4).builded multy agent system like writer agent,carrer agent,   ")
Result=app.invoke([input_msg])
print("\n-------output------\n")
for msg in Result:
  print(f"{type(msg).__name__}:{msg.content}\n")
